apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: example-onnx-mnist
  annotations:
    serving.kserve.io/deploymentMode: ModelMesh
spec:
  predictor:
    model:
      modelFormat:
        name: onnx
      runtime: ovms-1.x
      # this model can be downloaded by deploying the minio from this repo.
      storage:
        key: localMinIO
        path: onnx/mnist.onnx
        parameters: # Parameters to override the default values inside the common secret.
          bucket: modelmesh-example-models


# for kserve use path: openvino/mnist/